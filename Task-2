# Step 1: Data Collection
# Assume you have a dataset with food images in folders named after their classes
# E.g., Dataset structure: /data/train/class1, /data/train/class2, ...

# Step 2: Data Preprocessing
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Specify the data directory
data_directory = '/path/to/your/dataset'

# Create ImageDataGenerator for data augmentation and normalization
datagen = ImageDataGenerator(rescale=1./255,
                             shear_range=0.2,
                             zoom_range=0.2,
                             horizontal_flip=True,
                             validation_split=0.2)  # 80% for training, 20% for validation

# Load and preprocess the training dataset
train_generator = datagen.flow_from_directory(directory=data_directory,
                                              target_size=(224, 224),  # Adjust the target size based on your model architecture
                                              batch_size=32,
                                              class_mode='categorical',
                                              subset='training')

# Load and preprocess the validation dataset
validation_generator = datagen.flow_from_directory(directory=data_directory,
                                                   target_size=(224, 224),
                                                   batch_size=32,
                                                   class_mode='categorical',
                                                   subset='validation')

# Step 3: Model Architecture
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

# Load the pre-trained VGG16 model without the top (fully connected) layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Create a new model by adding custom fully connected layers on top of VGG16
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(train_generator.num_classes, activation='softmax'))

# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Step 4: Transfer Learning
# Compile the model with an appropriate optimizer, loss function, and metrics
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 5: Model Training
# Train the model on the training dataset
history = model.fit(train_generator, epochs=10, validation_data=validation_generator)

# Step 6: Model Evaluation
# Evaluate the model on the test set
test_generator = datagen.flow_from_directory(directory=data_directory,
                                             target_size=(224, 224),
                                             batch_size=32,
                                             class_mode='categorical')
test_loss, test_accuracy = model.evaluate(test_generator)

print("Test Accuracy:", test_accuracy)

# Step 7: Visualization
import matplotlib.pyplot as plt

# Plot training and validation accuracy over epochs
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Visualize model predictions on a few test images
sample_images, sample_labels = next(test_generator)
predictions = model.predict(sample_images)
predicted_classes = [train_generator.class_indices[class_label] for class_label in predictions.argmax(axis=1)]

# Display a few sample images with their predictions
for i in range(len(sample_images)):
    plt.imshow(sample_images[i])
    plt.title(f'Actual: {train_generator.index_to_label[sample_labels[i].argmax()]}\nPredicted: {train_generator.index_to_label[predicted_classes[i]]}')
    plt.show()
